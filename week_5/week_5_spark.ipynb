{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e035573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, types\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb5ca270",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/igor/spark/spark-3.0.3-bin-hadoop3.2/jars/spark-unsafe_2.12-3.0.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/02/28 16:19:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .master('local[*]')\n",
    "    .appName('test')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5400f65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0.3'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1\n",
    "spark.version\n",
    "\n",
    "# '3.0.3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a7d9a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-02-27 01:13:08--  https://nyc-tlc.s3.amazonaws.com/trip+data/fhvhv_tripdata_2021-02.csv\n",
      "Resolving nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)... 52.216.21.131\n",
      "Connecting to nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)|52.216.21.131|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 733822658 (700M) [text/csv]\n",
      "Saving to: ‘fhvhv_tripdata_2021-02.csv’\n",
      "\n",
      "fhvhv_tripdata_2021 100%[===================>] 699.83M  28.2MB/s    in 24s     \n",
      "\n",
      "2022-02-27 01:13:33 (29.1 MB/s) - ‘fhvhv_tripdata_2021-02.csv’ saved [733822658/733822658]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://nyc-tlc.s3.amazonaws.com/trip+data/fhvhv_tripdata_2021-02.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "238d60cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('hvfhs_license_num', types.StringType(), True),\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True),\n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True),\n",
    "    types.StructField('dropoff_datetime', types.TimestampType(), True),\n",
    "    types.StructField('PULocationID', types.IntegerType(), True),\n",
    "    types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "    types.StructField('SR_Flag', types.StringType(), True),\n",
    "    types.StructField('Affiliated_base_number', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba8bece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.read\n",
    "    .option('header', 'true')\n",
    "    .schema(schema)\n",
    "    .csv('./fhvhv_tripdata_2021-02.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3fa43c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58c750eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/27 01:13:44 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 7, schema size: 8\n",
      "CSV file: file:///home/igor/notebooks/fhvhv_tripdata_2021-02.csv\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet('fhfhv/2021/02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15997590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210M\t./fhfhv/2021/02/\r\n"
     ]
    }
   ],
   "source": [
    "# Q2\n",
    "!du -hs ./fhfhv/2021/02/\n",
    "\n",
    "# 210MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c294049a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet('fhfhv/2021/02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "915d11f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "367170"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3\n",
    "df.filter(F.to_date(df.pickup_datetime) == datetime(2021,2,15)).count()\n",
    "\n",
    "# 367170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "351970b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 14:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-------------------+-------------------+-----------------+\n",
      "|hvfhs_license_num|dispatching_base_num|    pickup_datetime|   dropoff_datetime|trip_duration_sec|\n",
      "+-----------------+--------------------+-------------------+-------------------+-----------------+\n",
      "|           HV0005|              B02510|2021-02-11 13:40:44|2021-02-12 10:39:44|            75540|\n",
      "|           HV0004|              B02800|2021-02-17 15:54:53|2021-02-18 07:48:34|            57221|\n",
      "|           HV0004|              B02800|2021-02-20 12:08:15|2021-02-21 00:22:14|            44039|\n",
      "|           HV0003|              B02864|2021-02-03 20:24:25|2021-02-04 07:41:58|            40653|\n",
      "|           HV0003|              B02887|2021-02-19 23:17:44|2021-02-20 09:44:01|            37577|\n",
      "|           HV0003|              B02764|2021-02-25 17:13:35|2021-02-26 02:57:05|            35010|\n",
      "|           HV0003|              B02875|2021-02-20 01:36:13|2021-02-20 11:16:19|            34806|\n",
      "|           HV0005|              B02510|2021-02-18 15:24:19|2021-02-19 01:01:11|            34612|\n",
      "|           HV0003|              B02764|2021-02-18 01:31:20|2021-02-18 11:07:15|            34555|\n",
      "|           HV0005|              B02510|2021-02-10 20:51:39|2021-02-11 06:21:08|            34169|\n",
      "|           HV0003|              B02764|2021-02-10 01:56:17|2021-02-10 10:57:33|            32476|\n",
      "|           HV0005|              B02510|2021-02-25 09:18:18|2021-02-25 18:18:57|            32439|\n",
      "|           HV0005|              B02510|2021-02-21 19:59:13|2021-02-22 04:56:16|            32223|\n",
      "|           HV0003|              B02864|2021-02-09 18:36:13|2021-02-10 03:31:00|            32087|\n",
      "|           HV0004|              B02800|2021-02-06 09:48:09|2021-02-06 18:32:16|            31447|\n",
      "|           HV0005|              B02510|2021-02-02 09:42:30|2021-02-02 18:17:43|            30913|\n",
      "|           HV0005|              B02510|2021-02-10 10:12:08|2021-02-10 18:46:24|            30856|\n",
      "|           HV0003|              B02764|2021-02-09 13:30:13|2021-02-09 22:02:25|            30732|\n",
      "|           HV0005|              B02510|2021-02-21 22:50:52|2021-02-22 07:21:52|            30660|\n",
      "|           HV0005|              B02510|2021-02-05 21:32:33|2021-02-06 06:01:04|            30511|\n",
      "+-----------------+--------------------+-------------------+-------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Q4\n",
    "(\n",
    "    df\n",
    "    .withColumn('trip_duration', F.to_timestamp(df.dropoff_datetime) - F.to_timestamp(df.pickup_datetime))\n",
    "    .withColumn('trip_duration_sec', F.to_timestamp(df.dropoff_datetime).cast('long') - F.to_timestamp(df.pickup_datetime).cast('long'))\n",
    "    .orderBy(F.col('trip_duration_sec').desc())\n",
    "    .select('hvfhs_license_num', 'dispatching_base_num', 'pickup_datetime', 'dropoff_datetime', 'trip_duration_sec')\n",
    "    .show()\n",
    ")\n",
    "\n",
    "# 2021-02-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2593acd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 31:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|dispatching_base_num|  count|\n",
      "+--------------------+-------+\n",
      "|              B02510|3233664|\n",
      "|              B02764| 965568|\n",
      "|              B02872| 882689|\n",
      "|              B02875| 685390|\n",
      "|              B02765| 559768|\n",
      "|              B02869| 429720|\n",
      "|              B02887| 322331|\n",
      "|              B02871| 312364|\n",
      "|              B02864| 311603|\n",
      "|              B02866| 311089|\n",
      "|              B02878| 305185|\n",
      "|              B02682| 303255|\n",
      "|              B02617| 274510|\n",
      "|              B02883| 251617|\n",
      "|              B02884| 244963|\n",
      "|              B02882| 232173|\n",
      "|              B02876| 215693|\n",
      "|              B02879| 210137|\n",
      "|              B02867| 200530|\n",
      "|              B02877| 198938|\n",
      "+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Q5\n",
    "df.groupBy(F.col('dispatching_base_num')).count().orderBy(F.col('count').desc()).show()\n",
    "\n",
    "# 2 stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36c3839",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = (\n",
    "    spark.read\n",
    "    .option('header', 'true')\n",
    "    .csv('./taxi+_zone_lookup.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ff313ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.registerTempTable('table_fhfhv')\n",
    "df_zones.registerTempTable('table_zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4121cabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:===================================>                  (132 + 4) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------+\n",
      "|               Zone|               Zone|count(1)|\n",
      "+-------------------+-------------------+--------+\n",
      "|      East New York|      East New York|   45041|\n",
      "|       Borough Park|       Borough Park|   37329|\n",
      "|           Canarsie|           Canarsie|   28026|\n",
      "|Crown Heights North|Crown Heights North|   25976|\n",
      "|          Bay Ridge|          Bay Ridge|   17934|\n",
      "+-------------------+-------------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 14:===============================================>      (176 + 4) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Q6\n",
    "spark.sql('''\n",
    "SELECT\n",
    "    t2.Zone, t3.Zone, COUNT(*)\n",
    "  FROM table_fhfhv t1\n",
    "  LEFT JOIN table_zones t2\n",
    "    ON t2.LocationID = t1.PULocationID\n",
    "  LEFT JOIN table_zones t3\n",
    "    ON t3.LocationID = t1.DOLocationID\n",
    " GROUP BY 1,2\n",
    " ORDER BY 3 DESC\n",
    " LIMIT 5\n",
    "''').show()\n",
    "\n",
    "# East New York East New York"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b8e15f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
